{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c366ba93-55d7-4a04-9d19-12e64868821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04e01087-acc7-452f-9e9f-8543f41801cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load qrels\n",
    "root = \"/gallery_louvre/dayoon.ko/research/sds/src/datasets/\"\n",
    "qrels_pth = root + \"nq-train/qrels/train.tsv\"\n",
    "qrels = pd.read_csv(qrels_pth, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07bb5d81-772f-498e-a3c0-c7e83eef2c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21564</th>\n",
       "      <td>train21564</td>\n",
       "      <td>doc2962294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24011</th>\n",
       "      <td>train24011</td>\n",
       "      <td>doc3299462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30983</th>\n",
       "      <td>train30983</td>\n",
       "      <td>doc4244915</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63770</th>\n",
       "      <td>train63770</td>\n",
       "      <td>doc8679304</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119508</th>\n",
       "      <td>train119508</td>\n",
       "      <td>doc16274486</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71268</th>\n",
       "      <td>train71268</td>\n",
       "      <td>doc9706714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126276</th>\n",
       "      <td>train126276</td>\n",
       "      <td>doc17189325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78607</th>\n",
       "      <td>train78607</td>\n",
       "      <td>doc10683762</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117954</th>\n",
       "      <td>train117954</td>\n",
       "      <td>doc16055865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5851</th>\n",
       "      <td>train5851</td>\n",
       "      <td>doc804139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           query-id    corpus-id  score\n",
       "21564    train21564   doc2962294      1\n",
       "24011    train24011   doc3299462      1\n",
       "30983    train30983   doc4244915      1\n",
       "63770    train63770   doc8679304      1\n",
       "119508  train119508  doc16274486      1\n",
       "...             ...          ...    ...\n",
       "71268    train71268   doc9706714      1\n",
       "126276  train126276  doc17189325      1\n",
       "78607    train78607  doc10683762      1\n",
       "117954  train117954  doc16055865      1\n",
       "5851      train5851    doc804139      1\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "qrels_sample = qrels.sample(n=1000, random_state=42)\n",
    "qrels_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b69a6088-c3f3-4f1c-832f-637d4b58de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_sample.to_csv(\"/gallery_louvre/dayoon.ko/research/sds/eval_retrieval/retrieval/results/bge-large-en-v1.5/nq.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8099b2-2ccb-4523-96ef-cb1e021f19a5",
   "metadata": {},
   "source": [
    "### Check corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88ce3be7-28c7-4a4e-b310-16d81ef0a137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load qrels\n",
    "import json\n",
    "root = \"/gallery_louvre/dayoon.ko/research/sds/src/datasets/\"\n",
    "corpus_train = root + \"nq-train/corpus.jsonl\"\n",
    "corpus_test = root + \"nq/corpus.jsonl\"\n",
    "with open(corpus_train) as f:\n",
    "    corpus_train = [json.loads(i) for i in f.readlines()]\n",
    "with open(corpus_test) as f:\n",
    "    corpus_test = [json.loads(i) for i in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d5e6ac5-d46e-4ec6-89fd-e5614bfb6b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18060996/18060996 [00:13<00:00, 1361816.31it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus_train_dict = {i[\"_id\"]: i for i in tqdm(corpus_train)}\n",
    "#corpus_test = [i for i in corpus_test if i[\"_id\"] in qrels[\"corpus-id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db13afe6-76c2-45de-8c15-9fc571fae531",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_corpus_train = [corpus_train_dict[cid] for cid in set(qrels[\"corpus-id\"].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21216c71-c360-4e60-be5b-c0b7f3365929",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_corpus_train_pth = root + \"nq-train/corpus_selected.jsonl\"\n",
    "with open(selected_corpus_train_pth, \"w\") as f:\n",
    "    for i in selected_corpus_train:\n",
    "        f.write(json.dumps(i) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dde3b38-cebe-412f-868f-747ce34fd4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132803"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_corpus_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f865f4b3-41a4-4288-b5f3-deabe757aeea",
   "metadata": {},
   "source": [
    "## Check fever and climate-fever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "230bf2fb-458f-4811-8719-08f762bbb9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5416568/5416568 [00:22<00:00, 237803.40it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5416593/5416593 [00:22<00:00, 241846.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load qrels\n",
    "import json\n",
    "root = \"/gallery_louvre/dayoon.ko/research/sds/src/datasets/\"\n",
    "corpus_fever = root + \"fever/corpus.jsonl\"\n",
    "corpus_climate_fever = root + \"climate-fever/corpus.jsonl\"\n",
    "with open(corpus_fever) as f:\n",
    "    corpus_fever = [json.loads(i)[\"_id\"] for i in tqdm(f.readlines())]\n",
    "with open(corpus_climate_fever) as f:\n",
    "    corpus_climate_fever = [json.loads(i)[\"_id\"] for i in tqdm(f.readlines())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c014a1e-0d91-47f8-9beb-77b486aa5d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2006_Texas_gubernatorial_election',\n",
       " '2007_Kangaroo_Island_bushfires',\n",
       " '2010_Northern_Hemisphere_heat_waves',\n",
       " '2010_United_Kingdom_general_election',\n",
       " '2015_United_Kingdom_general_election',\n",
       " '2017_United_Kingdom_general_election',\n",
       " '2018_British_Isles_heat_wave',\n",
       " '2019_United_Kingdom_general_election',\n",
       " '2019_heat_wave_in_India_and_Pakistan',\n",
       " '2019_in_science',\n",
       " '2019–20_Australian_bushfire_season',\n",
       " 'A_Scientific_Dissent_from_Darwinism',\n",
       " 'African_humid_period',\n",
       " 'Alcohol_(drug)',\n",
       " 'Angstrom',\n",
       " 'Art_Robinson',\n",
       " 'Avoiding_Dangerous_Climate_Change_(2005_conference)',\n",
       " 'Bernie_Sanders_2016_presidential_campaign',\n",
       " 'Climate_change_(general_concept)',\n",
       " 'Climate_change_in_Tuvalu',\n",
       " 'Climate_system',\n",
       " 'Climate_variability',\n",
       " 'Coral_in_non-tropical_regions',\n",
       " 'Donald_Trump_2016_presidential_campaign',\n",
       " 'Earth_shelter',\n",
       " 'Energy_subsidy',\n",
       " 'Explosive',\n",
       " 'Financial_crisis_of_2007–08',\n",
       " 'GRACE_and_GRACE-FO',\n",
       " 'Geysers_on_Mars',\n",
       " 'Global_Energy_and_Water_Exchanges',\n",
       " 'Global_temperature_record',\n",
       " 'Gravity_of_Mars',\n",
       " 'Human_impact_on_marine_life',\n",
       " 'Hurricane_Irma',\n",
       " 'Indo-Aryan_migration',\n",
       " 'Infrastructure_policy_of_Donald_Trump',\n",
       " 'John_Coleman_(meteorologist)',\n",
       " 'Lake_Worth_Beach,_Florida',\n",
       " 'Last_Glacial_Period',\n",
       " 'Media_coverage_of_global_warming',\n",
       " 'Microwave_Sounding_Unit_temperature_measurements',\n",
       " 'NW_Rota-1',\n",
       " 'OSTM/Jason-2',\n",
       " 'Retractions_in_academic_publishing',\n",
       " 'Rick_Perry_2012_presidential_campaign',\n",
       " 'Ron_Johnson_(Wisconsin_politician)',\n",
       " 'Scientific_consensus_on_climate_change',\n",
       " 'Second_Grinnell_expedition',\n",
       " 'Spanish_flu',\n",
       " 'Special_Report_on_Global_Warming_of_1.5_°C',\n",
       " 'Steele_dossier',\n",
       " 'The_Western_Journal',\n",
       " 'Tipping_points_in_the_climate_system',\n",
       " 'U.S._state_and_territory_temperature_extremes',\n",
       " 'United_Nations_Ocean_Conference',\n",
       " 'United_States_withdrawal_from_the_Paris_Agreement'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(corpus_climate_fever) - set(corpus_fever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "319f55b6-1376-4789-b367-5c7f0575381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load qrels\n",
    "import pandas as pd\n",
    "root = \"/gallery_louvre/dayoon.ko/research/sds/src/datasets/\"\n",
    "qrels_pth = root + \"climate-fever/qrels/test.tsv\"\n",
    "qrels = pd.read_csv(qrels_pth, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ce08f8b-e294-4138-b5db-32a202378860",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_ids = set(qrels[\"corpus-id\"].tolist()) - set(corpus_fever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5665a095-993d-4d05-bc4a-7185dabab84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import DirectoryLoader, DirectoryLoader, JSONLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "import os\n",
    "import fire\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "# Define the metadata extraction function.\n",
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "    del record[\"text\"]\n",
    "    metadata.update(record)\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e63aea3-1a83-40bc-abfd-b4b0679f33ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"climate-fever\"\n",
    "glob_dir:str = \"corpus.jsonl\"\n",
    "repo: str = \"BAAI\" #\"facebook\" #\"thenlper\" #\"intfloat\"\n",
    "model_name: str = \"bge-large-en-v1.5\" #\"contriever\" #\"gte-base\" #\"multilingual-e5-large\"\n",
    "data_dir: str = '/gallery_louvre/dayoon.ko/research/sds/src/datasets'\n",
    "db_faiss_dir: str = f\"../vectorstore/{model_name}/{dataset_name}\"\n",
    "batch_size: int = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a20ab1bf-426a-4b4c-99b6-5e51de7f73d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Document\n",
    "loader = JSONLoader(\n",
    "            f\"{data_dir}/{dataset_name}/{glob_dir}\", \n",
    "            jq_schema=\".\",  \n",
    "            content_key=\"text\",\n",
    "            json_lines=True,\n",
    "            metadata_func=metadata_func\n",
    "        )\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09badbfd-153f-45b0-b298-6b30b754fe5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5416593/5416593 [00:02<00:00, 1925383.48it/s]\n"
     ]
    }
   ],
   "source": [
    "documents = [i for i in tqdm(documents) if i.metadata[\"_id\"] in select_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a2a18ca-0b7f-4d27-a0c8-e80b136cd530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 'bge-large-en-v1.5')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents), model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70ac1b53-4fc4-4822-a388-8f2bcf9c0882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document count: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gallery_louvre/dayoon.ko/anaconda3/envs/dynamicer/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract db from documents ../vectorstore/bge-large-en-v1.5/climate-fever\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error in faiss::FileIOReader::FileIOReader(const char*) at /project/faiss/faiss/impl/io.cpp:68: Error: 'f' failed: could not open ../vectorstore/bge-large-en-v1.5/fever/index.faiss for reading: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_966723/4106809511.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#        embeddings,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#        normalize_L2 = True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#        distance_strategy=DistanceStrategy.MAX_INNER_PRODUCT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#    )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdb_org\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"../vectorstore/{model_name}/fever\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dangerous_deserialization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mdb_org\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Saving embeddings to {db_faiss_dir}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mdb_org\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{db_faiss_dir}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dynamicer/lib/python3.10/site-packages/langchain_community/vectorstores/faiss.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(cls, folder_path, embeddings, index_name, allow_dangerous_deserialization, **kwargs)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             )\n\u001b[1;32m   1089\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0;31m# load index separately since it is not picklable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0mfaiss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdependable_faiss_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"{index_name}.faiss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m         \u001b[0;31m# load docstore and index_to_docstore_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34mf\"{index_name}.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dynamicer/lib/python3.10/site-packages/faiss/swigfaiss.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   9848\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9849\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_swigfaiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Error in faiss::FileIOReader::FileIOReader(const char*) at /project/faiss/faiss/impl/io.cpp:68: Error: 'f' failed: could not open ../vectorstore/bge-large-en-v1.5/fever/index.faiss for reading: No such file or directory"
     ]
    }
   ],
   "source": [
    "print(f'Document count: {len(documents)}')\n",
    "\n",
    "# Split document\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "                model_name=f\"{repo}/{model_name}\",\n",
    "                model_kwargs={\n",
    "                    'device': 'cpu',\n",
    "                },\n",
    "                encode_kwargs={\n",
    "                    'batch_size': batch_size,\n",
    "                    'device': 'cpu',\n",
    "                }\n",
    "            )    # Make a DB\n",
    "\n",
    "print(f'Extract db from documents {db_faiss_dir}')\n",
    "#db = FAISS.from_documents(\n",
    "#        documents, \n",
    "#        embeddings,\n",
    "#        normalize_L2 = True,\n",
    "#        distance_strategy=DistanceStrategy.MAX_INNER_PRODUCT\n",
    "#    )\n",
    "db_org = FAISS.load_local(f\"../vectorstore/{model_name}/fever\", embeddings=embeddings, allow_dangerous_deserialization=True) \n",
    "db_org.add_documents(documents)\n",
    "print(f'Saving embeddings to {db_faiss_dir}')\n",
    "db_org.save_local(f'{db_faiss_dir}')\n",
    "print('Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a70079b-de00-4412-a788-0f071b694850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
